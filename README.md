# ðŸ§  DIFFUSION MODEL â€” CORE MECHANISM

Your model has **only one job**:

> Learn how to **remove noise**.

Thatâ€™s it.

Not image generation.
Not digit drawing.

Just **noise removal**.

Everything else comes from that.

---

# ðŸ” TWO PROCESSES EXIST

```
FORWARD PROCESS   â†’ destroy image
REVERSE PROCESS   â†’ rebuild image
```

---

# 1ï¸âƒ£ FORWARD DIFFUSION (DESTROYING DATA)

You start with a clean image:

```
xâ‚€ = real MNIST digit
```

Example:

```
7
```

Now you add **tiny Gaussian noise** step by step.

---

## At each timestep t:

```
xâ‚ = image + small noise
xâ‚‚ = image + more noise
...
x_T = pure noise
```

After enough steps:

```
x_T â‰ˆ N(0, I)
```

Pure random noise.

---

## Formula used:

```
x_t = âˆšÎ±Ì„_t Â· xâ‚€  +  âˆš(1 âˆ’ Î±Ì„_t) Â· Îµ
```

Where:

* Îµ = random Gaussian noise
* Î±Ì„â‚œ = cumulative product of noise schedule

Meaning:

* early t â†’ mostly image
* late t â†’ mostly noise

---

### ðŸ”¥ Important insight

You **never add noise repeatedly**.

You jump directly from xâ‚€ â†’ xâ‚œ in one step.

Thatâ€™s why training is fast.

---

# 2ï¸âƒ£ WHAT THE MODEL LEARNS

The UNet **does NOT predict the image**.

It predicts:

```
Îµ  (the noise)
```

Why?

Because noise is:

* simple
* Gaussian
* stable

Predicting images directly is unstable.

---

## Training target:

```
model(x_t, t, label) â‰ˆ Îµ
```

---

### During training:

You already know the noise because you generated it.

So you minimize:

```
Loss = MSE(predicted_noise, true_noise)
```

Thatâ€™s it.

---

# 3ï¸âƒ£ WHY TIME EMBEDDING EXISTS

The same noisy image can appear at different steps.

The model must know:

> â€œHow noisy is this image?â€

So you give it:

```
timestep t
```

Converted into a vector using **sinusoidal embeddings**.

Same idea as Transformers.

---

### Time embedding answers:

> â€œAre we at step 5 or step 195?â€

---

# 4ï¸âƒ£ WHY LABEL EMBEDDING EXISTS

You want:

```
digit 3
digit 7
digit 9
```

from the same noise distribution.

So you embed the class label:

```
label â†’ vector
```

Then inject it into the UNet.

Now the model learns:

> â€œWhen label = 3, denoise like a 3.â€

---

# 5ï¸âƒ£ WHAT YOUR UNET IS ACTUALLY DOING

Input:

```
x_t      â†’ noisy image
t_emb    â†’ time embedding
label_emb â†’ digit class
```

Output:

```
predicted_noise ÎµÌ‚
```

---

## Architecture logic

```
Downsampling â†’ understand structure
Bottleneck   â†’ combine time + label
Upsampling   â†’ reconstruct image
```

Skip connections preserve details.

---

# 6ï¸âƒ£ REVERSE DIFFUSION (GENERATION)

This is where magic happens.

---

### Step 1

Start from pure noise:

```
x_T ~ N(0, I)
```

---

### Step 2

For t = T â†’ 0:

```
x_{t-1} = denoise(x_t)
```

At every step:

* model predicts noise
* removes a bit of it
* adds small randomness

---

### Update equation:

```
x_{tâˆ’1} =
  1/âˆšÎ±_t ( x_t âˆ’ Î²_t ÎµÌ‚ / âˆš(1 âˆ’ Î±Ì„_t) )
  + Ïƒ_t z
```

This slowly reveals structure.

---

### What actually happens visually

```
random static
â†“
blur
â†“
digit shape
â†“
clear digit
```

---

# 7ï¸âƒ£ WHY THIS ACTUALLY GENERATES IMAGES

Because your model learned:

> â€œIf something looks like this noise pattern,
> remove noise in THIS direction.â€

Over millions of examples, it learns the **data distribution**.

---

# 8ï¸âƒ£ WHY THIS IS NOT GAN

| GAN                 | Diffusion            |
| ------------------- | -------------------- |
| One-shot generation | Iterative generation |
| Unstable            | Very stable          |
| Hard to train       | Easy                 |
| Mode collapse       | No collapse          |
| Fast                | Slower               |

Diffusion trades speed for stability.

---

# 9ï¸âƒ£ WHY STABLE DIFFUSION WORKS

Stable Diffusion is just:

```
your model
+ latent space
+ text conditioning
+ larger UNet
```

Nothing conceptually different.

---

# ðŸ”¥ FINAL MECHANISM SUMMARY

```
1. Take real image xâ‚€
2. Add noise â†’ x_t
3. Train UNet to predict noise Îµ
4. Give timestep embedding
5. Give label embedding
6. Reverse process removes noise step-by-step
7. Image emerges from randomness
```

---

# ðŸ§  IF WE UNDERSTAND THISâ€¦

We can understand:

* DDPM
* Stable Diffusion
* Imagen
* DALLÂ·E diffusion core
* All modern image generators

Only scale changes.

---

# ðŸŽ¯ ONE-SENTENCE EXPLANATION

> A diffusion model learns how to gradually remove noise from random data until a structured image appears.

---

