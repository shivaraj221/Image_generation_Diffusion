{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BVTmkdIC5NX",
        "outputId": "152eb514-0804-424d-f77a-844b5003b532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:01<00:00, 5.53MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 14.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Loss: 0.1147\n",
            "Epoch 2/100 | Loss: 0.0719\n",
            "Epoch 3/100 | Loss: 0.0641\n",
            "Epoch 4/100 | Loss: 0.0601\n",
            "Epoch 5/100 | Loss: 0.0582\n",
            "Epoch 6/100 | Loss: 0.0565\n",
            "Epoch 7/100 | Loss: 0.0552\n",
            "Epoch 8/100 | Loss: 0.0546\n",
            "Epoch 9/100 | Loss: 0.0538\n",
            "Epoch 10/100 | Loss: 0.0529\n",
            "Epoch 11/100 | Loss: 0.0525\n",
            "Epoch 12/100 | Loss: 0.0518\n",
            "Epoch 13/100 | Loss: 0.0517\n",
            "Epoch 14/100 | Loss: 0.0513\n",
            "Epoch 15/100 | Loss: 0.0506\n",
            "Epoch 16/100 | Loss: 0.0503\n",
            "Epoch 17/100 | Loss: 0.0501\n",
            "Epoch 18/100 | Loss: 0.0499\n",
            "Epoch 19/100 | Loss: 0.0500\n",
            "Epoch 20/100 | Loss: 0.0495\n",
            "Epoch 21/100 | Loss: 0.0489\n",
            "Epoch 22/100 | Loss: 0.0489\n",
            "Epoch 23/100 | Loss: 0.0490\n",
            "Epoch 24/100 | Loss: 0.0487\n",
            "Epoch 25/100 | Loss: 0.0482\n",
            "Epoch 26/100 | Loss: 0.0481\n",
            "Epoch 27/100 | Loss: 0.0482\n",
            "Epoch 28/100 | Loss: 0.0482\n",
            "Epoch 29/100 | Loss: 0.0477\n",
            "Epoch 30/100 | Loss: 0.0479\n",
            "Epoch 31/100 | Loss: 0.0478\n",
            "Epoch 32/100 | Loss: 0.0474\n",
            "Epoch 33/100 | Loss: 0.0473\n",
            "Epoch 34/100 | Loss: 0.0471\n",
            "Epoch 35/100 | Loss: 0.0470\n",
            "Epoch 36/100 | Loss: 0.0471\n",
            "Epoch 37/100 | Loss: 0.0468\n",
            "Epoch 38/100 | Loss: 0.0470\n",
            "Epoch 39/100 | Loss: 0.0468\n",
            "Epoch 40/100 | Loss: 0.0469\n",
            "Epoch 41/100 | Loss: 0.0467\n",
            "Epoch 42/100 | Loss: 0.0465\n",
            "Epoch 43/100 | Loss: 0.0467\n",
            "Epoch 44/100 | Loss: 0.0464\n",
            "Epoch 45/100 | Loss: 0.0465\n",
            "Epoch 46/100 | Loss: 0.0463\n",
            "Epoch 47/100 | Loss: 0.0462\n",
            "Epoch 48/100 | Loss: 0.0461\n",
            "Epoch 49/100 | Loss: 0.0457\n",
            "Epoch 50/100 | Loss: 0.0462\n",
            "Epoch 51/100 | Loss: 0.0462\n",
            "Epoch 52/100 | Loss: 0.0457\n",
            "Epoch 53/100 | Loss: 0.0459\n",
            "Epoch 54/100 | Loss: 0.0457\n",
            "Epoch 55/100 | Loss: 0.0456\n",
            "Epoch 56/100 | Loss: 0.0454\n",
            "Epoch 57/100 | Loss: 0.0456\n",
            "Epoch 58/100 | Loss: 0.0457\n",
            "Epoch 59/100 | Loss: 0.0454\n",
            "Epoch 60/100 | Loss: 0.0457\n",
            "Epoch 61/100 | Loss: 0.0455\n",
            "Epoch 62/100 | Loss: 0.0455\n",
            "Epoch 63/100 | Loss: 0.0455\n",
            "Epoch 64/100 | Loss: 0.0452\n",
            "Epoch 65/100 | Loss: 0.0453\n",
            "Epoch 66/100 | Loss: 0.0453\n",
            "Epoch 67/100 | Loss: 0.0453\n",
            "Epoch 68/100 | Loss: 0.0453\n",
            "Epoch 69/100 | Loss: 0.0453\n",
            "Epoch 70/100 | Loss: 0.0451\n",
            "Epoch 71/100 | Loss: 0.0452\n",
            "Epoch 72/100 | Loss: 0.0450\n",
            "Epoch 73/100 | Loss: 0.0449\n",
            "Epoch 74/100 | Loss: 0.0449\n",
            "Epoch 75/100 | Loss: 0.0450\n",
            "Epoch 76/100 | Loss: 0.0452\n",
            "Epoch 77/100 | Loss: 0.0449\n",
            "Epoch 78/100 | Loss: 0.0451\n",
            "Epoch 79/100 | Loss: 0.0447\n",
            "Epoch 80/100 | Loss: 0.0447\n",
            "Epoch 81/100 | Loss: 0.0450\n",
            "Epoch 82/100 | Loss: 0.0447\n",
            "Epoch 83/100 | Loss: 0.0448\n",
            "Epoch 84/100 | Loss: 0.0448\n",
            "Epoch 85/100 | Loss: 0.0447\n",
            "Epoch 86/100 | Loss: 0.0447\n",
            "Epoch 87/100 | Loss: 0.0447\n",
            "Epoch 88/100 | Loss: 0.0446\n",
            "Epoch 89/100 | Loss: 0.0447\n",
            "Epoch 90/100 | Loss: 0.0445\n",
            "Epoch 91/100 | Loss: 0.0445\n",
            "Epoch 92/100 | Loss: 0.0445\n",
            "Epoch 93/100 | Loss: 0.0445\n",
            "Epoch 94/100 | Loss: 0.0446\n",
            "Epoch 95/100 | Loss: 0.0445\n",
            "Epoch 96/100 | Loss: 0.0445\n",
            "Epoch 97/100 | Loss: 0.0443\n",
            "Epoch 98/100 | Loss: 0.0443\n",
            "Epoch 99/100 | Loss: 0.0445\n",
            "Epoch 100/100 | Loss: 0.0443\n",
            "Step 150\n",
            "Step 100\n",
            "Step 50\n",
            "Step 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# üß† CONDITIONAL DIFFUSION MODEL (MNIST Example) - FIXED\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ Setup\n",
        "# ============================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "IMAGE_SHAPE = (1, 28, 28)\n",
        "BATCH_SIZE = 64\n",
        "NO_EPOCHS = 100\n",
        "LR = 0.001\n",
        "PRINT_FREQ = 2\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ Data\n",
        "# ============================================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda t: (t * 2) - 1),  # scale to [-1, 1]\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "reverse_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda t: (t + 1) / 2),\n",
        "    transforms.Lambda(lambda t: t.squeeze(0)),\n",
        "])\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ Diffusion Process\n",
        "# ============================================================\n",
        "class DiffusionModel:\n",
        "    def __init__(self, timesteps=200, start_beta=1e-4, end_beta=0.02, device=device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        self.betas = torch.linspace(start_beta, end_beta, timesteps).to(device)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "\n",
        "    def get_index_from_list(self, vals, t, x_shape):\n",
        "        batch_size = t.shape[0]\n",
        "        out = vals.gather(-1, t)\n",
        "        return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "    def forward(self, x_0, t, device):\n",
        "        noise = torch.randn_like(x_0)\n",
        "        sqrt_alpha = self.get_index_from_list(self.alphas_cumprod.sqrt(), t, x_0.shape)\n",
        "        sqrt_one_minus_alpha = self.get_index_from_list(torch.sqrt(1 - self.alphas_cumprod), t, x_0.shape)\n",
        "        x_t = sqrt_alpha * x_0 + sqrt_one_minus_alpha * noise\n",
        "        return x_t, noise\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def backward(self, x, t, model, labels):\n",
        "        beta_t = self.get_index_from_list(self.betas, t, x.shape)\n",
        "        sqrt_one_minus_alpha = self.get_index_from_list(torch.sqrt(1 - self.alphas_cumprod), t, x.shape)\n",
        "        sqrt_recip_alpha = self.get_index_from_list(torch.sqrt(1.0 / self.alphas), t, x.shape)\n",
        "\n",
        "        pred_noise = model(x, t, labels)\n",
        "        mean = sqrt_recip_alpha * (x - beta_t * pred_noise / sqrt_one_minus_alpha)\n",
        "        if t[0] == 0:\n",
        "            return mean\n",
        "        noise = torch.randn_like(x)\n",
        "        sigma = torch.sqrt(beta_t)\n",
        "        return mean + sigma * noise\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ Time Embedding\n",
        "# ============================================================\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, t):\n",
        "        half = self.dim // 2\n",
        "        freq = torch.exp(torch.arange(half, device=t.device) * (-math.log(10000) / (half - 1)))\n",
        "        emb = t[:, None] * freq[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ Conditional UNet (FIXED - Correct Channel Dimensions)\n",
        "# ============================================================\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, num_classes=10, down=True):\n",
        "        super().__init__()\n",
        "        self.down = down\n",
        "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
        "        self.label_emb = nn.Embedding(num_classes, out_ch)\n",
        "\n",
        "        if down:\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)  # Downsample\n",
        "        else:\n",
        "            # FIXED: Correct input channels for upsampling (concatenated)\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)  # Upsample\n",
        "\n",
        "        self.batchnorm = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t, labels):\n",
        "        h = self.relu(self.conv1(x))\n",
        "        time_emb = self.relu(self.time_mlp(t))[(...,) + (None,)*2]\n",
        "        label_emb = self.relu(self.label_emb(labels))[(...,) + (None,)*2]\n",
        "        h = h + time_emb + label_emb\n",
        "        h = self.relu(self.batchnorm(self.conv2(h)))\n",
        "        return self.transform(h)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, img_ch=1, time_emb_dim=128, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.time_emb = SinusoidalPositionEmbeddings(time_emb_dim)\n",
        "\n",
        "        # Down path\n",
        "        self.down1 = Block(img_ch, 64, time_emb_dim, num_classes, down=True)\n",
        "        self.down2 = Block(64, 128, time_emb_dim, num_classes, down=True)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck_conv1 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bottleneck_conv2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bottleneck_bn = nn.BatchNorm2d(128)\n",
        "        self.bottleneck_time_mlp = nn.Linear(time_emb_dim, 128)\n",
        "        self.bottleneck_label_emb = nn.Embedding(num_classes, 128)\n",
        "\n",
        "        # Up path (FIXED: Correct input channels with skip connections)\n",
        "        self.up1 = Block(256, 128, time_emb_dim, num_classes, down=False)  # 128 + 128 from skip\n",
        "        self.up2 = Block(192, 64, time_emb_dim, num_classes, down=False)   # 128 + 64 from skip\n",
        "\n",
        "        self.out = nn.Conv2d(64, img_ch, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t, labels):\n",
        "        t_emb = self.time_emb(t)\n",
        "\n",
        "        # Down path with skip connections\n",
        "        d1 = self.down1(x, t_emb, labels)      # 64 channels, 14x14\n",
        "        d2 = self.down2(d1, t_emb, labels)     # 128 channels, 7x7\n",
        "\n",
        "        # Bottleneck\n",
        "        h = self.relu(self.bottleneck_conv1(d2))\n",
        "        time_emb = self.relu(self.bottleneck_time_mlp(t_emb))[(...,) + (None,)*2]\n",
        "        label_emb = self.relu(self.bottleneck_label_emb(labels))[(...,) + (None,)*2]\n",
        "        h = h + time_emb + label_emb\n",
        "        b = self.relu(self.bottleneck_bn(self.bottleneck_conv2(h)))  # 128 channels, 7x7\n",
        "\n",
        "        # Up path with skip connections\n",
        "        u1 = torch.cat([b, d2], dim=1)         # Concatenate: 128 + 128 = 256 channels\n",
        "        u1 = self.up1(u1, t_emb, labels)       # 128 channels, 14x14\n",
        "\n",
        "        u2 = torch.cat([u1, d1], dim=1)        # Concatenate: 128 + 64 = 192 channels\n",
        "        u2 = self.up2(u2, t_emb, labels)       # 64 channels, 28x28\n",
        "\n",
        "        return self.out(u2)\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ Training\n",
        "# ============================================================\n",
        "diffusion = DiffusionModel(device=device)\n",
        "model = UNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "for epoch in range(NO_EPOCHS):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        t = torch.randint(0, diffusion.timesteps, (x.size(0),), device=device).long()\n",
        "        x_t, noise = diffusion.forward(x, t, device)\n",
        "        pred_noise = model(x_t, t, y)\n",
        "        loss = F.mse_loss(pred_noise, noise)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}/{NO_EPOCHS} | Loss: {np.mean(losses):.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ Sampling (Generate digits)\n",
        "# ============================================================\n",
        "model.eval()\n",
        "\n",
        "label = torch.tensor([3]).to(device)  # generate a \"9\"\n",
        "x = torch.randn((1, 1, 28, 28)).to(device)\n",
        "for i in reversed(range(diffusion.timesteps)):\n",
        "    t = torch.full((1,), i, dtype=torch.long, device=device)\n",
        "    x = diffusion.backward(x, t, model, label)\n",
        "    if i % 50 == 0:\n",
        "        print(f\"Step {i}\")\n",
        "\n",
        "plt.imshow(reverse_transform(x[0].cpu()).detach().cpu(), cmap=\"gray\")\n",
        "plt.title(\"Generated digit: 3\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZhAm2XGDAc6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}